source("http://bioconductor.org/biocLite.R")
biocLite("GeneticsPed")
library(GeneticsPed)   # load GeneticsPed package
rm(list=ls())   # remove everything from memory in the working environment
getwd()
source("GenomicRel.R")  # source function GenomicRel() for future calls
Markers=read.table("Marker.txt")   # read Marker data
ped=read.table("ped.ped")  # read associated pedigree file
View(Markers)
head(ped.ped)
head(ped)
# 5 different genomic relationship matrices can be obtained as follows:
GOF=GenomicRel(1,Markers,ped)
GD=GenomicRel(2,Markers,ped)
G05=GenomicRel(3,Markers,ped)
GMF=GenomicRel(4,Markers,ped)
Greg=GenomicRel(5,Markers,ped)
head(GOF)
head(GD)
# Create data frame called CorrOpt.
CorrOpt=data.frame(row=GOF[,1],col=GOF[,2],A=GOF[,4],
GOF=GOF[,3],GD=GD[,3], G05=G05[,3],GMF=GMF[,3],Greg=Greg[,3])
head(CorrOpt)
# Correlation matrix is computed below (the first two columns are excluded)
cortable=cor(CorrOpt[,c(-1,-2)])
plot(cortable)
head(cortable)
heatmap(cortable)
# round the correlation values to 3 significant digits
round(cortable,3)
# 3.  Give summary statistics (mean, min and max) for the inbreeding coefficients
# for each of the G matrices and the A matrix
Inbreed=subset(CorrOpt,row-col==0)   # Take the diagonals of the matrix
Rel=subset(CorrOpt,row-col!=0)    # Take the off diagonals of the matrix
maxI=apply(Inbreed,2,max)
maxR=apply(Rel,2,max)
minI=apply(Inbreed,2,min)
minR=apply(Rel,2,min)
meanI=apply(Inbreed,2,mean)
meanR=apply(Rel,2,mean)
summary=t(rbind(meanI,minI,maxI,meanR,minR,maxR))[c(-1,-2),]
summary
library(genetics)   #install/load package
library(GeneticsPed)  #installed by Bioconductor source option
# Reading pedigree file
pedigree<-read.table("C165pedmatrix.csv",header=T, sep=",")
head(pedigree)
# Reading marker file
genos <-read.table("Genotype_c.csv", header=T, sep=",")
# this function is provided. It generates G matrices using different methods
source("RelFxn.R")
# Generating G matrix based on the regression method (option=2)
Ginv2 <-GenomicRel(option=2,data=genos, ped=pedigree, sort=F)
# View the first 5 lines of G inverse matrix
View(Ginv2)
dim(Ginv2)  # Get dimensions row-col
# Save the G inverse matrix we created above (Ginv2) to working folder,
# Name it as ‘Ginv.giv’, there are no row and column names.
# Separator of field is one space
write.table(Ginv2,"Ginv2.giv",row.names=F,col.names=F,sep=" ")
head(ped)
https://www.r-bloggers.com/gblup-example-in-r/
#begin
library(package="MatrixModels")
dat <- data.frame( y=c(1.5, 2.35, 3.4, 2.31, 1.53),
s1=c("AA", "Aa", "Aa", "AA", "aa"),
s2=c("Bb", "BB", "bb", "BB", "bb"),
s3=c("cc", "Cc", "Cc", "cc", "CC"),
s4=c("Dd", "Dd", "DD", "dd", "Dd"))
dat
cols <- paste("s", 1:4, sep="")
dat[, cols] <- lapply(dat[, cols], function(z) as.integer(z) - 1)
dat
(y <- dat$y)
(X <- model.Matrix(y ~  1,                     data=dat, sparse=TRUE))
(Z <- model.Matrix(y ~ -1 + s1 + s2 + s3 + s4, data=dat, sparse=TRUE))
XX <- crossprod(X)
XZ <- crossprod(X, Z)
ZZ <- crossprod(Z)
Xy <- crossprod(X, y)
Zy <- crossprod(Z, y)
(LHS <- rBind(cBind(XX,    XZ),
cBind(t(XZ), ZZ + Diagonal(n=dim(ZZ)[1]) * lambda)))
(RHS <- rBind(Xy,
Zy))
(sol <- solve(LHS, RHS))
(GEBV <- Z %*% sol[-1])
y
(X <- model.Matrix(y ~  1,                     data=dat, sparse=TRUE))
(Z <- model.Matrix(y ~ -1 + s1 + s2 + s3 + s4, data=dat, sparse=TRUE))
XX <- crossprod(X)
X
proc.time()
library(pedigree)
install.packages(pkg='devtools',repos='https://cran.r-project.org/')  #1# install devtools
library(devtools)                                                     #2# load the library
install_git('https://github.com/Rpedigree/pedigreeR/')                #3# install pedigreeR from GitHub
install.packages("pedigree")
library(pedigree)
h2 <- 0.5
example(SamplePedigree)
head(pedigree)
head(phList)
ped <- phList$ped
hList <- phList$hList
qtlList <- ListQTL(hList = hList,frqtl = 0.1,sigma2qtl = 1)
qtl <- tapply(unlist(qtlList),list(rep(names(qtlList),times = unlist(lapply(qtlList,length))),
unlist(lapply(qtlList,function(x)seq(1,length(x))))),mean,na.rm = TRUE)
qtl <- melt(qtl)
ped
hList
qtlList
qtl
unlist(lapply(qtlList,function(x)seq(1,length(x))))),mean,na.rm = TRUE)
qtl <- melt(qtl)
names(qtl) <- c("POS","TRAIT","a")
HH <- getAll(hList,translatePos = FALSE)
rownames(HH) <- sapply(hList,function(x)x@hID)
QQ <- HH[,match(qtl$POS,colnames(HH))]
g <- QQ
ped$G <- with(ped,g[match(hID0,rownames(g))]+g[match(hID1,rownames(g))])
sigmae <- sqrt(var(ped$G)/h2 - var(ped$G))
ped$P <- ped$G + rnorm(nrow(ped),0,sigmae)
M <- with(ped,HH[match(hID0,rownames(HH)),] + HH[match(hID1,rownames(HH)),])
rownames(M) <- ped$ID
sol <- gblup(P~1,data = ped[,c('ID','P')],M = M,lambda = 1/h2 - 1)
library(rrBULP)
library(rrBULP)
install.packages("rrBLUP")
library(rrBULP)
library(rrBLUP)
getwd()
load("E:/GoogleDrive/My_Scripts/R学习/rrBLUP/snp.txt")
setwd("C:/")
setwd("E:/GoogleDrive/My_Scripts/R学习/rrBLUP")
Markers<-as.matrix(read.table("snp.txt"))
head(Markers)
Pheno<-as.matrix(read.table("traits.txt"))
head(Pheno)
head(Pheno,header=T)
Pheno<-as.matrix(read.table("traits.txt",header=T))
head(Pheno)
head(Markers[:3,:3])
head(Markers[1:3,1:3])
impute=A.mat(Markers,max.missing=0.5,impute.method="mean",return.imputed=T)
head(impute)
impute$A
impute$imputed
Markers_impute2=Markers_impute[,c(169,562)]
#Rename imputed marker matrix as Markers_impute
Markers_impute=impute$imputed
Markers_impute2=Markers_impute[,c(169,562)]
head(Markers_impute2)
which(is.na(Markers_impute) = T)
which(is.na(Markers_impute) == T)
is.na(Markers_impute)
Markers_impute2=Markers_impute[,-c(169,562)]
head(Markers_impute2)
train = as.matrix(sample(1:96,58))
head(train)
test <- setdiff(1:96,train)
test
Pheno_train = Pheno[train, ]
m_train = Markers_impute2[train, ]
Pheno_valid = Pheno[test, ]
m_valid = Markers_impute2[test, ]
Pheno_train
m_train
Pheno_valid
# Run Mixed.solve
yeild = (Pheno_train[,1])
yeild_answer= mixed.solve(yield,Z = m_train, K = NULL, SE =FALSE, return.Hinv= FALSE)
# Run Mixed.solve
yeild = (Pheno_train[,1])
yeild_answer= mixed.solve(yield,Z = m_train, K = NULL, SE =FALSE, return.Hinv= FALSE)
# Run Mixed.solve
yield = (Pheno_train[,1])
yield_answer= mixed.solve(yield,Z = m_train, K = NULL, SE =FALSE, return.Hinv= FALSE)
yield
yield_answer
YLD <-yield_answer$u
YLD <-yield_answer$u
YLD
e = as.matrix(YLD)
head(e)
pred_yield_valid = m_valid %*% e
pred_yield = (predi_yield_valid[,1])+ yield_answer$beta
pred_yield
pred_yield_valid = m_valid %*% e
pred_yield = (predi_yield_valid[,1])+ yield_answer$beta
pred_yield = (pred_yield_valid[,1])+ yield_answer$beta
pred_yield
traits = 1
cycles =500
accuracy = matrix (nrow = cycles, ncol = traits)
for (r in 1:cycles){
train = as.matrix(sample(1:96,38))
test = setdiff(1:96, train)
Pheno_valid = Pheno[train,]
m_valid = Markers_impute2[test,]
Yield = (pheno_train[,1])
yield_answer= mixed.solve(yield,Z = m_train, K = NULL, SE =FALSE, return.Hinv= FALSE)
YLD <-yield_answer$u
e = as.matrix(YLD)
pred_yield_valid = m_valid %*% e
pred_yield = (pred_yield_valid[,1])+ yield_answer$beta
pred_yield
yield_valid = Pheno_valid[,1]
accuracy[r,1] <-cor (pred_yield_valid,yield_valid.use="complete")
}
traits = 1
cycles =500
accuracy = matrix (nrow = cycles, ncol = traits)
for (r in 1:cycles){
train = as.matrix(sample(1:96,38))
test = setdiff(1:96, train)
Pheno_valid = Pheno[train,]
m_valid = Markers_impute2[test,]
Yield = (Pheno_train[,1])
yield_answer= mixed.solve(yield,Z = m_train, K = NULL, SE =FALSE, return.Hinv= FALSE)
YLD <-yield_answer$u
e = as.matrix(YLD)
pred_yield_valid = m_valid %*% e
pred_yield = (pred_yield_valid[,1])+ yield_answer$beta
pred_yield
yield_valid = Pheno_valid[,1]
accuracy[r,1] <-cor (pred_yield_valid,yield_valid.use="complete")
}
traits = 1
cycles =500
accuracy = matrix (nrow = cycles, ncol = traits)
for (r in 1:cycles){
train = as.matrix(sample(1:96,38))
test = setdiff(1:96, train)
Pheno_valid = Pheno[train,]
m_valid = Markers_impute2[test,]
Yield = (Pheno_train[,1])
yield_answer= mixed.solve(yield,Z = m_train, K = NULL, SE =FALSE, return.Hinv= FALSE)
YLD <-yield_answer$u
e = as.matrix(YLD)
pred_yield_valid = m_valid %*% e
pred_yield = (pred_yield_valid[,1])+ yield_answer$beta
pred_yield
yield_valid = Pheno_valid[,1]
accuracy[r,1] <-cor (pred_yield_valid,yield_valid,use="complete")
}
train = as.matrix(sample(1:96,38))
test = setdiff(1:96, train)
Pheno_valid = Pheno[train,]
m_valid = Markers_impute2[test,]
Yield = (Pheno_train[,1])
yield_answer= mixed.solve(yield,Z = m_train, K = NULL, SE =FALSE, return.Hinv= FALSE)
YLD <-yield_answer$u
e = as.matrix(YLD)
pred_yield_valid = m_valid %*% e
pred_yield = (pred_yield_valid[,1])+ yield_answer$beta
pred_yield
yield_valid = Pheno_valid[,1]
accuracy[r,1] <-cor (pred_yield_valid,yield_valid,use="complete")
cor (pred_yield_valid,yield_valid,use="complete")
pred_yield_valid
yield_valid
e
pred_yield_valid = m_valid %*% e
pred_yield_valid
pred_yield = (pred_yield_valid[,1])+ yield_answer$beta
pred_yield
accuracy[r,1] <-cor (pred_yield_valid,yield_valid,use="complete")
dim(pred_yield_valid)
dim(yield_valid)
yield_valid = Pheno_valid[,1]
Pheno_valid[,1]
Pheno_valid = Pheno[test, ]
Pheno_valid
Pheno_valid[,1]
accuracy[r,1] <-cor (pred_yield_valid,yield_valid,use="complete")
yield_valid
yield_valid = Pheno_valid[,1]
yiled_valid
yield_valid
accuracy[r,1] <-cor (pred_yield_valid,yield_valid,use="complete")
for (r in 1:cycles){
train = as.matrix(sample(1:96,38))
test = setdiff(1:96, train)
Pheno_valid = Pheno[train,]
m_valid = Markers_impute2[test,]
Yield = (Pheno_train[,1])
yield_answer= mixed.solve(yield,Z = m_train, K = NULL, SE =FALSE, return.Hinv= FALSE)
YLD <-yield_answer$u
e = as.matrix(YLD)
pred_yield_valid = m_valid %*% e
pred_yield = (pred_yield_valid[,1])+ yield_answer$beta
pred_yield
yield_valid = Pheno_valid[,1]
accuracy[r,1] <-cor (pred_yield_valid,yield_valid,use="complete")
}
Pheno_valid = Pheno[test, ]
ion Accuracy
traits = 1
cycles =500
accuracy = matrix (nrow = cycles, ncol = traits)
for (r in 1:cycles){
train = as.matrix(sample(1:96,38))
test = setdiff(1:96, train)
Pheno_valid = Pheno[train,]
m_valid = Markers_impute2[test,]
Yield = (Pheno_train[,1])
yield_answer= mixed.solve(yield,Z = m_train, K = NULL, SE =FALSE, return.Hinv= FALSE)
YLD <-yield_answer$u
e = as.matrix(YLD)
pred_yield_valid = m_valid %*% e
pred_yield = (pred_yield_valid[,1])+ yield_answer$beta
pred_yield
yield_valid = Pheno_valid[,1]
accuracy[r,1] <-cor (pred_yield_valid,yield_valid,use="complete")
}
mean(accuracy)
Pheno_valid
Pheno_valid = Pheno[test, ]
Pheno_valid
traits = 1
cycles =500
accuracy = matrix (nrow = cycles, ncol = traits)
for (r in 1:cycles){
train = as.matrix(sample(1:96,38))
test = setdiff(1:96, train)
Pheno_train = Pheno[train,]
m_valid = Markers_impute2[test,]
Yield = (Pheno_train[,1])
yield_answer= mixed.solve(yield,Z = m_train, K = NULL, SE =FALSE, return.Hinv= FALSE)
YLD <-yield_answer$u
e = as.matrix(YLD)
pred_yield_valid = m_valid %*% e
pred_yield = (pred_yield_valid[,1])+ yield_answer$beta
pred_yield
yield_valid = Pheno_valid[,1]
accuracy[r,1] <-cor (pred_yield_valid,yield_valid,use="complete")
}
mean(accuracy)
traits = 1
cycles =500
accuracy = matrix (nrow = cycles, ncol = traits)
for (r in 1:cycles){
train = as.matrix(sample(1:96,38))
test = setdiff(1:96, train)
Pheno_train = Pheno[train,]
m_valid = Markers_impute2[test,]
Yield = (Pheno_train[,1])
yield_answer= mixed.solve(yield,Z = m_train, K = NULL, SE =FALSE, return.Hinv= FALSE)
YLD <-yield_answer$u
e = as.matrix(YLD)
pred_yield_valid = m_valid %*% e
pred_yield = (pred_yield_valid[,1])+ yield_answer$beta
pred_yield
yield_valid = Pheno_valid[,1]
accuracy[r,1] <-cor (pred_yield_valid,yield_valid,use="complete")
}
mean(accuracy) # 0.49
## Set Working Director for PC
setwd("E:/GoogleDrive/My_Scripts/R学习/BLUP_R_example_tomato")
## Read in Brix dataset
qualdat = read.csv("TBRTQuality.csv", header=T)
## Check to ensure data imported correctly
str(qualdat)
head(qualdat)
tail(qualdat)
## Attach dataset
attach(qualdat)
## Examine distribution of brix data
hist(Brix, col="gold")
boxplot(Brix~Loc, xlab="Location", ylab="Degrees Brix", main="Degrees Brix by Location", col="pink")
# Rename variables for ease of use
BRIX = as.numeric(Brix)
LINE = as.factor(Line)
LOC = as.factor(Loc)
YEAR = as.factor(Year)
REP = as.factor(Rep)
## Calculate variance components
# requires lme4 package
library(lme4)
# Linear Model with random effects for variance components
brixvarcomp = lmer(BRIX~ (1|LINE) + (1|LOC) + (1|YEAR) + (1|REP%in%LOC:YEAR) + (1|LINE:LOC) + (1|LINE:YEAR))
brixvarcomp = lmer(Brix~ (1|Line) + (1|Loc) + (1|Year) + (1|(Rep:Loc):Year) + (1|Line:Loc) + (1|Line:Year))
brixvarcomp = lmer(BRIX~ (1|LINE) + (1|LOC) + (1|YEAR) + (1|REP%in%LOC:YEAR) + (1|LINE:LOC) + (1|LINE:YEAR),control=lmerControl(check.nlev.gtr.1="ignore"))"
# Extract variance components
summary(brixvarcomp)
## BLUPS
# fit the model
brixmodel = lmer(BRIX ~ (1|LINE) + (1|LOC) + (1|YEAR) + (1|REP%in%LOC:YEAR) + (1|LINE:LOC) + (1|LINE:YEAR))
# estimate BLUPS
brixblup = ranef(brixmodel)
# look at output structure
str(brixblup)
# extract blup for line
brixlineblup = brixblup$LINE
# see the structure of the blup for each line
str(brixlineblup)
# save the brixlineblup output to a separate .csv file
write.csv(brixlineblup, file="BrixLineBLUPS.csv")
## Creating plots with the BLUPs
# Create a numeric vector with the BLUP for each line
LINEBLUP = brixlineblup[,1]
# Create a histogram with the BLUP for each line
hist(LINEBLUP, col="brown")
## Compare BLUP to line averages on a scatterplot
lmean = tapply(BRIX, LINE, na.rm=T, mean)
plot(LINEBLUP, lmean, col="blue")
# Linear Model with random effects for variance components
brixvarcomp = lmer(BRIX~ (1|LINE) + (1|LOC) + (1|YEAR) + (1|REP%in%LOC:YEAR) + (1|LINE:LOC) + (1|LINE:YEAR))
## Set Working Director for PC
setwd("E:/GoogleDrive/My_Scripts/R学习/BLUPS_tomato")
## Read in Brix dataset
qualdat = read.csv("TBRTQuality.csv", header=T)
## Check to ensure data imported correctly
str(qualdat)
head(qualdat)
tail(qualdat)
## Attach dataset
attach(qualdat)
## Examine distribution of brix data
hist(Brix, col="gold")
boxplot(Brix~Loc, xlab="Location", ylab="Degrees Brix", main="Degrees Brix by Location", col="pink")
#qxs
hist(pH);hist(TA)
boxplot(Brix ~ pH)
# Rename variables for ease of use
BRIX = as.numeric(Brix)
LINE = as.factor(Line)
LOC = as.factor(Loc)
YEAR = as.factor(Year)
REP = as.factor(Rep)
## Calculate variance components
# requires lme4 package
library(lme4)
# Linear Model with random effects for variance components
brixvarcomp = lmer(BRIX~ (1|LINE) + (1|LOC) + (1|YEAR) + (1|REP%in%LOC:YEAR) + (1|LINE:LOC) + (1|LINE:YEAR))
BRIX = as.numeric(Brix)
LINE = as.factor(Line)
LOC = as.factor(Loc)
YEAR = as.factor(Year)
REP = as.factor(Rep)
BRIX
#Error: grouping factors must have > 1 sampled level
brixvarcomp = lmer(Brix~ (1|Line) + (1|Loc) + (1|Year) + (1|(Rep:Loc):Year) + (1|Line:Loc) + (1|Line:Year))
brixvarcomp = lmer(BRIX~ (1|LINE) + (1|LOC) + (1|YEAR) + (1|REP%in%LOC:YEAR) + (1|LINE:LOC) + (1|LINE:YEAR),
control=lmerControl(check.nlev.gtr.1="ignore"))
# Extract variance components
summary(brixvarcomp)
## BLUPS
# fit the model
brixmodel = lmer(BRIX ~ (1|LINE) + (1|LOC) + (1|YEAR) + (1|REP%in%LOC:YEAR) + (1|LINE:LOC) + (1|LINE:YEAR))
brixmodel = lmer(BRIX~ (1|LINE) + (1|LOC) + (1|YEAR) + (1|REP%in%LOC:YEAR) + (1|LINE:LOC) + (1|LINE:YEAR),
control=lmerControl(check.nlev.gtr.1="ignore"))
# estimate BLUPS for each line, then use blups for our selection
brixblup = ranef(brixmodel)
# look at output structure
str(brixblup)
# extract blup for each line (what we are interested in this case)
brixlineblup = brixblup$LINE
# see the structure of the blup for each line
str(brixlineblup)
# save the brixlineblup output to a separate .csv file
write.csv(brixlineblup, file="BrixLineBLUPS.csv")
## Creating plots with the BLUPs
# Create a numeric vector with the BLUP for each line
LINEBLUP = brixlineblup[,1]
# Create a histogram with the BLUP for each line
hist(LINEBLUP, col="brown")
## Compare BLUP to line averages on a scatterplot
lmean = tapply(BRIX, LINE, na.rm=T, mean)
plot(LINEBLUP, lmean, col="blue")
